View(dfA)
dfA$X1
dfA[X1]
dfA['X1']
for (i in 1:35){
dfA['X'+toString(i)] <- GroupA[(i*4-3):i*4]
}
'X'+toString(3)
for (i in 1:35){
dfA[paste('X',toString(i), sep="")] <- GroupA[(i*4-3):i*4]
}
GroupA[(i*4-3):i*4]
i
(i*4-3):i*4
2:10
9:12
for (i in 1:35){
dfA[paste('X',toString(i), sep="")] <- GroupA[(i*4-3):(i*4)]
}
dfA[paste('X',toString(i), sep="")] <- data0[GroupA[(i*4-3):(i*4)]]
for (i in 1:35){
dfA[paste('X',toString(i), sep="")] <- data0[GroupA[(i*4-3):(i*4)]]
}
View(dfA)
for (i in 1:35){
dfA[paste('X',toString(i), sep="")] <- data0[GroupA[(i*4-3):(i*4)]]
dfB[paste('X',toString(i), sep="")] <- data0[-GroupA[(i*4-3):(i*4)]]
}
i
-GroupA[(i*4-3):(i*4)]
data0[-GroupA[(i*4-3):(i*4)]]
B = matrix(0, 3,35)
dfA = data.frame(A)
dfB = data.frame(B)
for (i in 1:35){
dfA[paste('X',toString(i), sep="")] <- data0[GroupA[(i*4-3):(i*4)]]
dfB[paste('X',toString(i), sep="")] <- data0[-GroupA[(i*4-3):(i*4)]]
}
View(dfA)
View(dfB)
df = rbind(dfA, dfB)
View(df)
df[1:5,]
mean(df[1:5,])
means = colMeans(dfA)-colMeans(dfB)
means
diff = mean(data0[1:4])-(data0[5:7])
diff = mean(data0[1:4])-mean(data0[5:7])
sum(abs(means)>abs(diff))
sum(abs(means)>=abs(diff))
install.packages("stargazer")
library(stargazer)
stargazer(df)
install.packages("xtable")
library(xtable)
print(xtable)
print(df)
print(df, floating = FLASE)
df.table<-xtable(df)
print(df.table, floating=FALSE)
df = t(df)
df = rbind(dfA, dfB)
df = rbind(df,means)
View(df)
df = t(df)
View(df)
rename(df,c("row.names"="Combinations", "8"="mean"))
names(df)
names(df)
df
names(df) = c('Combinations','1','2','3','4','5','6','7','mean')
View(df)
names(df)
df.table<- xtable(df)
print(df.table)
print(df.table, floating=FALSE)
p=sum(means>=diff)/35
sum(means>=diff)
p=sum(abs(means)>=abs(diff))/35
p
p*35
diff
print(df.table, floating=FALSE)
library(data.table)
naps = data.table(exp(rnorm(40)))
naps = data.table(ability=exp(rnorm(40)))
View(naps)
naps[,noNap:rpois(40,ability)]
View(naps)
naps[,noNap:=rpois(40,ability)]
View(naps)
naps[,nap:rpois(40, ability+1)]
naps[,nap:=rpois(40, ability+1)]
View(naps)
libarary(ggplot2)
library(ggplot2)
View(naps)
ggplot(npas, (aes(x=(nap-nonap))))
ggplot(npas, (aes(x=(nap-nonap))))+geom_histogram()
ggplot(naps, (aes(x=(nap-nonap))))+geom_histogram()
ggplot(naps, (aes(x=(nap-noNap))))+geom_histogram()
head(naps)
library(data.table)
naps = data.table(exp(rnorm(40)))
naps = data.table(ability=exp(rnorm(40)))
naps[,noNap:=rpois(40,ability)]
naps[,nap:=rpois(40, ability+1)]
library(ggplot2)
ggplot(naps, (aes(x=(nap-noNap))))+geom_histogram()
head(naps)
naps[(nap - noNap) != 0, (nap - noNap)<0]
sum(naps[(nap - noNap) != 0, (nap - noNap)<0])
sum(naps[(nap - noNap) != 0, (nap - noNap)>0])
length(naps)
length(naps[(nap - noNap) != 0, (nap - noNap)>0])
sum(naps[(nap - noNap) != 0, (nap - noNap)>0])
length(naps[(nap - noNap) != 0, (nap - noNap)>0])
binom.test(25, 33)
library(MASS)
wilcox.test(naps$nap, naps$noNap, paired=TRUE)
p2b = NULL
for (i in 1:10000){
X2b = rnorm(100)
z = (sum(X2b>0)-50)/5
p2b[i] = pnorm(z)
}
p2b = data.frame(p2b)
ggplot(p2b,aes(x=p2b)) + geom_histogram(binwidth=0.05)+geom_vline(xintercept = 0.05, color="red")+
theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))
#Q2 (a)
p2a = NULL
for (i in 1:10000){
X2a = rnorm(100)
t = mean(X2a)/sd(X2a)*10
p2a[i] = pt(t, 99)
}
p2a = data.frame(p2a)
ggplot(p2a,aes(x=p2a)) + geom_histogram(binwidth=0.05)+geom_vline(xintercept = 0.05, color="red")+
theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))
ggsave(file='2a.png', width=5, heigh=5, dpi=300)
ppt2a = sum(p2a < 0.05)
#Q2(b)
p2b = NULL
for (i in 1:10000){
X2b = rnorm(100)
z = (sum(X2b>0)-50)/5
p2b[i] = pnorm(z)
}
p2b = data.frame(p2b)
ggplot(p2b,aes(x=p2b)) + geom_histogram(binwidth=0.05)+geom_vline(xintercept = 0.05, color="red")+
theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))ggsave(file='2b.png', width=5, heigh=5, dpi=300)
ppt2b = sum(p2b < 0.05)
library(ggplot2)
p2b = NULL
for (i in 1:10000){
X2b = rnorm(100)
z = (sum(X2b>0)-50)/5
p2b[i] = pnorm(z)
}
p2b = data.frame(p2b)
ggplot(p2b,aes(x=p2b)) + geom_histogram(binwidth=0.05)+geom_vline(xintercept = 0.05, color="red")+
theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))ggsave(file='2b.png', width=5, heigh=5, dpi=300)
ppt2b = sum(p2b < 0.05)
#Q2 (a)
p2a = NULL
for (i in 1:10000){
X2a = rnorm(100)
t = mean(X2a)/sd(X2a)*10
p2a[i] = pt(t, 99)
}
p2a = data.frame(p2a)
ggplot(p2a,aes(x=p2a)) + geom_histogram(binwidth=0.05)+geom_vline(xintercept = 0.05, color="red")+
theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))
ggsave(file='2a.png', width=5, heigh=5, dpi=300)
ppt2a = sum(p2a < 0.05)
#Q2(b)
p2b = NULL
for (i in 1:10000){
X2b = rnorm(100)
z = (sum(X2b>0)-50)/5
p2b[i] = pnorm(z)
}
p2b = data.frame(p2b)
ggplot(p2b,aes(x=p2b)) + geom_histogram(binwidth=0.05)+geom_vline(xintercept = 0.05, color="red")+
theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))ggsave(file='2b.png', width=5, heigh=5, dpi=300)
ppt2b = sum(p2b < 0.05)
p2b = data.frame(p2b)
ggplot(p2b,aes(x=p2b)) + geom_histogram(binwidth=0.05)+geom_vline(xintercept = 0.05, color="red")+
theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))
ggsave(file='2b.png', width=5, heigh=5, dpi=300)
#Q2(b)
p2b = NULL
for (i in 1:10000){
X2b = rnorm(100)
z = (sum(X2b>0)-50)/5
p2b[i] = pnorm(z)
}
p2b = data.frame(p2b)
ggplot(p2b,aes(x=p2b)) + geom_histogram(binwidth=0.1)+geom_vline(xintercept = 0.05, color="red")+
theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))
ggsave(file='2b.png', width=5, heigh=5, dpi=300)
#Q2(b)
p2b = NULL
for (i in 1:10000){
X2b = rnorm(100)
z = (sum(X2b>0)-50)/5
p2b[i] = pnorm(z)
}
p2b = data.frame(p2b)
ggplot(p2b,aes(x=p2b)) + geom_histogram(binwidth=0.1)+geom_vline(xintercept = 0.05, color="red")+
theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))
ggsave(file='2b.png', width=5, heigh=5, dpi=300)
p2b = NULL
for (i in 1:10000){
X2b = rnorm(100)
z = (sum(X2b>0)-50)/5
p2b[i] = pnorm(z)
}
p2b = data.frame(p2b)
ggplot(p2b,aes(x=p2b)) + geom_histogram(binwidth=0.75)+geom_vline(xintercept = 0.05, color="red")+
theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))
ggsave(file='2b.png', width=5, heigh=5, dpi=300)
p2b = NULL
for (i in 1:10000){
X2b = rnorm(100)
z = (sum(X2b>0)-50)/5
p2b[i] = pnorm(z)
}
p2b = data.frame(p2b)
ggplot(p2b,aes(x=p2b)) + geom_histogram(binwidth=0.075)+geom_vline(xintercept = 0.05, color="red")+
theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))
ggsave(file='2b.png', width=5, heigh=5, dpi=300)
library("tcltk", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
load("/Users/tianlan/Google Drive/STAT221/STAT221/HW3/out/task2a.rda")
d = list(d$A)
data = d
theta.sgd  = apply(theta.sgd, 2, function(colum)
log(t(colum) %*% data[[1]] %*% (colum)))
theta.asgd  = apply(theta.asgd, 2, function(colum)
log(t(colum) %*% data$[[1]] %*% (colum)))
theta.asgd  = apply(theta.asgd, 2, function(colum)
log(t(colum) %*% data[[1]] %*% (colum)))
theta.asgd.bad  = apply(theta.asgd.bad, 2, function(colum)
log(t(colum) %*% data[[1]] %*% (colum)))
theta.batch  = apply(theta.batch, 2, function(colum)
log(t(colum) %*% data[[1]] %*% (colum)))
theta.sgd.im = apply(theta.sgd.im, 2, function(colum)
log(t(colum) %*% data[[1]] %*% (colum)))
x = seq(1, length(theta.batch))
x = 1+(x-1)*50
agg = data.frame(x, theta.sgd, theta.asgd, theta.asgd.bad, theta.batch, theta.sgd.im)
select = c(floor(1.1^(1:103)),2e4)
agg = agg[select, ]
agg = melt(agg, id = 'x')
ggplot(agg, aes(x = x, y = value, color = variable)) + geom_line()+scale_x_log10(limits=c(200, 1e6))+
xlab('Iterations')+ylab('excess risk')
source('lan_tian_ps3_functions.R')
library(ggplot2)
setwd("~/Google Drive/STAT221/STAT221/HW3")
source('lan_tian_ps3_functions.R')
library(ggplot2)
agg = melt(agg, id = 'x')
library(reshape)
library(reshape2)
agg = melt(agg, id = 'x')
ggplot(agg, aes(x = x, y = value, color = variable)) + geom_line()+scale_x_log10(limits=c(200, 1e6))+
xlab('Iterations')+ylab('excess risk')
test = sampe.data2a(1000)
source('lan_tian_ps3_functions.R')
#library(ggplot2)
sample.data2a <-function(dim.n){
Q = random.orthogonal(100)
lambdas = c(rep(1, 3), rep(0.02, 97))
A = Q %*% diag(lambdas) %*% t(Q)
X = matrix(rnorm(100*dim.n), nrow = dim.n)
return (list(A=A, X=X))
}
test = sampe.data2a(1000)
test = sample.data2a(1000)
test$A
sum(diag(test$A))
sum(c(rep(1, 3), rep(0.02, 97)))
# Copyright (c) 2013
# Panos Toulis, ptoulis@fas.harvard.edu
#
# Using the simulation setup as in glmnet JoSS paper(Friedman, Hastie, Tibshirani)
# http://www.jstatsoft.org/v33/i01/
#
# EXAMPLE run:
#  run.glmnet(1e4, 10)
#
rm(list=ls())
library(mvtnorm)
library(glmnet)
# genjerry, genx2 are functions taken from the above paper.
# These functions generate the simulation data.
# NOTE: use function sample.data(..) instead.
genjerry = function(x, snr){
# generate data according to Friedman's setup
n=nrow(x)
p=ncol(x)
b=((-1)^(1:p))*exp(-2*((1:p)-1)/20)
# b=sample(c(-0.8, -0.45, 0.45, 0.9, 1.4), size=p, replace=T)
# ((-1)^(1:p))*(1:p)^{-0.65}#exp(-2*((1:p)-1)/20)
f=x%*%b
e=rnorm(n)
k=sqrt(var(f)/(snr*var(e)))
y=f+k*e
return(list(y=y, beta=b))
}
genx2 = function(n,p,rho){
#    generate x's multivariate normal with equal corr rho
# Xi = b Z + Wi, and Z, Wi are independent normal.
# Then Var(Xi) = b^2 + 1
#  Cov(Xi, Xj) = b^2  and so cor(Xi, Xj) = b^2 / (1+b^2) = rho
z=rnorm(n)
if(abs(rho)<1){
beta=sqrt(rho/(1-rho))
x0=matrix(rnorm(n*p),ncol=p)
A = matrix(z, nrow=n, ncol=p, byrow=F)
x= beta * A + x0
}
if(abs(rho)==1){ x=matrix(z,nrow=n,ncol=p,byrow=F)}
return(x)
}
sample.data <- function(dim.n, dim.p, rho=0.0, snr=1) {
# Samples the dataset according to Friedman et. al.
#
# 1. sample covariates
X = genx2(dim.n, dim.p, rho)
# 2. ground truth params.
theta = ((-1)^(1:dim.p))*exp(-2*((1:dim.p)-1)/20)
f= X %*% theta
e = rnorm(dim.n)
k= sqrt(var(f)/(snr*var(e)))
y=f+k*e
return(list(y=y, X=X, theta=theta, tr=1/(1-rho)*dim.p))
}
dist <- function(x, y) {
if(length(x) != length(y))
stop("MSE should compare vectors of same length")
sqrt(mean((x-y)^2))
}
plot.risk <- function(data, est) {
# est = p x niters
est.bias = apply(est, 2, function(colum)
dist(colum, data$theta))
plot(est.bias, type="l", lty=3)
}
sgd <- function(data, plot=T) {
# check.data(data)
n = nrow(data$X)
p = ncol(data$X)
# matrix of estimates of SGD (p x iters)
theta.sgd = matrix(0, nrow = p, ncol = n)
# params for the learning rate seq.
gamma0 = 1 / data$tr
lambda0 = 1
for(i in 1:(n-1)) {
xi = data$X[i, ]
theta.old = theta.sgd[, i]
ai = gamma0 / (1 + gamma0 * lambda0 * i)
# make computations easier.
lpred = sum(theta.old * xi)
theta.new = (theta.old - ai * lpred * xi) + ai * data$y[i] * xi
theta.sgd[, i+1] = theta.new
}
if(plot) {
plot.risk(data, theta.sgd)
} else {
return(theta.sgd)
}
}
# Main function to run this experiment.
run.sgd <- function(dim.n, dim.p,
rho.values=c(0.0, 0.1, 0.2, 0.5, 0.9, 0.95),
nreps=3,
verbose=F) {
## Runs glmnet() for various param values.
##
niters = 0
cols = c("rho", "rep", "time", "mse")
timings = matrix(nrow=0, ncol=length(cols))
colnames(timings) <- cols
rownames(timings) = NULL
total.iters = nreps * length(rho.values)
pb = txtProgressBar(style=3)
seeds=sample(1:1e9, size=total.iters)
for(i in 1:nreps) {
for(rho in rho.values) {
niters = niters + 1
set.seed(seeds[niters])
# 1. (For every repetition) Sample the dataset
dataset = sample.data(dim.n=dim.n, dim.p=dim.p, rho=rho, snr=3.0)
true.theta = dataset$theta
x = dataset$X
y = dataset$y
stopifnot(nrow(x) == dim.n, ncol(x) == dim.p)
# 1b. Define metrics:
#   dt = time for the method to finish
#   mse = Distance (e.g. RMSE) of the estimates to the ground truth.
#         (q1, q2, q3) representing the quartiles (since glmnet returns grid of estimates)
#         Implicit has (x, x, x) i.e., the same value in all places.
new.dt = 0
new.mse = NA
# 2. Run the method.
new.dt = system.time({ fit = sgd(dataset, plot=F)})[1]
new.mse = dist(fit[, ncol(fit)], true.theta)
# 3. Tabulate timings
timings = rbind(timings, c(rho, i,
new.dt,
new.mse))
setTxtProgressBar(pb, niters/total.iters)
}
}
return(timings)
}
sgd.im <- function(data, plot=T) {
# check.data(data)
n = nrow(data$X)
p = ncol(data$X)
# matrix of estimates of SGD (p x iters)
theta.sgd = matrix(0, nrow = p, ncol = n)
# params for the learning rate seq.
gamma0 = 1 / data$tr
lambda0 = 1
for(i in 1:(n-1)) {
xi = data$X[i, ]
theta.old = theta.sgd[, i]
ai = 1 / ( lambda0 + lambda0 * i)
# make computations easier.
inner = sum(xi^2)
ratio = 1/(1+inner*ai)
lpred = sum(theta.old * xi)
theta.new = theta.old + ai*(data$y[i]-lpred*ratio-ai*data$y[i]*ratio*inner)*xi
theta.sgd[, i+1] = theta.new
}
if(plot) {
plot.risk(data, theta.sgd)
} else {
return(theta.sgd)
}
}
# Main function to run this experiment.
run.sgd.im <- function(dim.n, dim.p,
rho.values=c(0.0, 0.1, 0.2, 0.5, 0.9, 0.95),
nreps=3,
verbose=F) {
## Runs glmnet() for various param values.
##
niters = 0
cols = c("rho", "rep", "time", "mse")
timings = matrix(nrow=0, ncol=length(cols))
colnames(timings) <- cols
rownames(timings) = NULL
total.iters = nreps * length(rho.values)
pb = txtProgressBar(style=3)
seeds=sample(1:1e9, size=total.iters)
for(i in 1:nreps) {
for(rho in rho.values) {
niters = niters + 1
set.seed(seeds[niters])
# 1. (For every repetition) Sample the dataset
dataset = sample.data(dim.n=dim.n, dim.p=dim.p, rho=rho, snr=3.0)
true.theta = dataset$theta
x = dataset$X
y = dataset$y
stopifnot(nrow(x) == dim.n, ncol(x) == dim.p)
# 1b. Define metrics:
#   dt = time for the method to finish
#   mse = Distance (e.g. RMSE) of the estimates to the ground truth.
#         (q1, q2, q3) representing the quartiles (since glmnet returns grid of estimates)
#         Implicit has (x, x, x) i.e., the same value in all places.
new.dt = 0
new.mse = NA
# 2. Run the method.
new.dt = system.time({ fit = sgd(dataset, plot=F)})[1]
new.mse = dist(fit[, ncol(fit)], true.theta)
# 3. Tabulate timings
timings = rbind(timings, c(rho, i,
new.dt,
new.mse))
setTxtProgressBar(pb, niters/total.iters)
}
}
return(timings)
}
cleanup <-function(data){
reps= nrow(data)/6
for (i in 1:6){
for (j in 1:(reps-1)){
data[i, ] = data[i, ] + data[i+6*j, ]
}
data[i, ] = data[i, ]/reps
}
data[1:6, ]
}
reps = 3
P = c(1000, 5000, 20000, 50000)
for (p in P){
print(sprintf('n = %d, p = %d', 100, p))
result = run.sgd(100, p)
result = cleanup(result)
print(result)
}
N = c(1000, 5000)
for (n in N){
print(sprintf('im: n = %d, p = %d', n, 100))
result = run.sgd.im(n, 100)
result = cleanup(result)
print(result)
}
