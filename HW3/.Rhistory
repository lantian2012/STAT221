theta.new = theta.old + a[i]*(data$A %*% (xi - theta.old))
theta.sgd[, 1] = theta.new
theta.new = (1-1/(i+1))*theta.old + 1/(i+1)*theta.new
theta.asgd[, i+1] = theta.new
}
if (plot){
plot.risk2a(data, theta.asgd)
}
else{
return (theta.asgd)
}
}
asgd.bad<-function(data, plot = T){
n = nrow(data$X)
p = ncol(data$X)
theta.asgd = matrix(0.1, nrow = p, ncol = n+1)
a = (1+seq(1, n))^(-0.5)
for (i in 1:n){
xi = data$X[i, ]
theta.old = theta.asgd[, i]
theta.new = theta.old + a[i]*(data$A %*% (xi - theta.old))
if (i > 1){
theta.new = (1-1/i)*theta.old + 1/i*theta.new
}
theta.asgd[, i+1] = theta.new
}
if (plot){
plot.risk2a(data, theta.asgd)
}
else{
return (theta.asgd)
}
}
batch <- function(data, plot = T){
n = nrow(data$X)
p = ncol(data$X)
theta.batch = matrix(0, nrow = p, ncol = n+1)
a = (1+seq(1, n))^(-0.5)
for (i in 1:n){
xi = data$X[i, ]
if (i == 1){
theta.new = xi
}
else{
theta.old = theta.batch[, i-1]
theta.new = (1-1/i)*theta.old + 1/i*xi
}
theta.batch[, i] = theta.new
}
if (plot){
plot.risk2a(data, theta.batch)
}
else{
return (theta.batch)
}
}
d = sample.data2a(1e4)
theta.sgd = sgd(d, F)
theta.sgd.im = sgd.im(d, F)
theta.asgd = asgd(d, F)
theta.asgd.bad = asgd.bad(d, F)
theta.batch = batch(d, F)
plot.all(d, theta.sgd, theta.asgd, theta.asgd.bad, theta.batch, theta.sgd.im)
sgd(d)
asgd(d)
asgd<-function(data, plot=T) {
# check.data(data)
n = nrow(data$X)
p = ncol(data$X)
# matrix of estimates of SGD (p x iters)
theta.sgd = matrix(1, nrow=p, ncol=n+1)
theta.asgd = matrix(1, nrow=p, ncol=n+1)
# params for the learning rate seq.
gamma0 = 1
delta0 = 0.02
for(i in 1:n) {
xi = data$X[i, ]
theta.old = theta.sgd[, i]
gammai = 1 / (1 + delta0 * i) ^ (2/3)
# make computations easier.
theta.new = theta.old - gammai * ((2 * data$A) %*% (theta.old - xi))
theta.sgd[, i+1] = theta.new
theta.asgd[, i+1] = (theta.asgd[, i] * i + theta.new) / (i+1)
}
if(plot) {
plot.risk(data, theta.asgd, log=T)
} else {
return(theta.asgd)
}
}
asgd(d)
plot.risk <- function(data, theta, log=T) {
excess.risk = get.risk(data, theta, log)
plot(excess.risk, type="l", lty=3)
}
asgd(d)
get.risk <- function(data, theta, log=T) {
excess.risk = apply(theta, 2, function(column) (t(column-data$theta) %*% data$A %*% (column-data$theta)))
if(log){
excess.risk = log(excess.risk)
}
return(excess.risk)
}
asgd(d)
sample.data <- function(dim.n,dim.p,model="gaussian") {
# Samples the covariates as normal with the specific correlation
# Create A matrix (variance of the covariates xn)
Q = random.orthogonal(p=dim.p)
eigens = c(rep(1,3),rep(0.02,dim.p-3))
A = Q %*% diag(eigens) %*% t(Q)
theta = matrix(0, ncol=1, nrow=dim.p)
X = rmvnorm(dim.n, mean=theta, sigma=diag(dim.p))
epsilon = rnorm(dim.n, mean=0, sd=1)
# Data generation
y = X %*% theta  + epsilon
return(list(Y=y, X=X, A=A, theta=theta))
}
data = sample.data(1e4, 100)
asgd(data)
asgd<-function(data, plot = T){
n = nrow(data$X)
p = ncol(data$X)
theta.asgd = matrix(0.1, nrow = p, ncol = n+1)
theta.sgd = matrix(0, nrow = p, ncol = 1)
a = (1+0.02*seq(1, n))^(-2/3)
for (i in 1:n){
xi = data$X[i, ]
theta.old = theta.sgd[, 1]
theta.new = theta.old + a[i]*(data$A %*% (xi - theta.old))
theta.sgd[, 1] = theta.new
theta.new = (1-1/(i+1))*theta.old + 1/(i+1)*theta.new
theta.asgd[, i+1] = theta.new
}
if (plot){
plot.risk2a(data, theta.asgd)
}
else{
return (theta.asgd)
}
}
asgd(data)
asgd<-function(data, plot = T){
n = nrow(data$X)
p = ncol(data$X)
theta.asgd = matrix(0.1, nrow = p, ncol = n+1)
theta.sgd = matrix(0, nrow = p, ncol = 1)
a = (1+0.02*seq(1, n))^(-2/3)
for (i in 1:n){
xi = data$X[i, ]
theta.old = theta.sgd[, 1]
theta.new = theta.old + a[i]*(data$A %*% (xi - theta.old))
theta.sgd[, 1] = theta.new
theta.new = (1-1/(i+1))*theta.asgd[, i] + 1/(i+1)*theta.new
theta.asgd[, i+1] = theta.new
}
if (plot){
plot.risk2a(data, theta.asgd)
}
else{
return (theta.asgd)
}
}
asgd(data)
plot.risk2a <- function(data, est) {
# est = p x niters
est.bias = apply(est, 2, function(colum)
log(t(colum) %*% data$A %*% (colum)))
x = 1:(length(est.bias))
plot(x, est.bias, type="l", lty=3)
}
asgd(data)
sgd(data)
d = sample.data(1e5, 100)
theta.sgd = sgd(d, F)
theta.sgd.im = sgd.im(d, F)
library(mvtnorm)
source('lan_tian_ps3_functions.R')
sample.data <- function(dim.n, dim.p, model="gaussian") {
# Samples the covariates as normal with the specific correlation
# Create A matrix (variance of the covariates xn)
Q = random.orthogonal(p=dim.p)
lambdas = seq(0.01, 1, length.out=dim.p)
A = Q %*% diag(lambdas) %*% t(Q)
X = rmvnorm(dim.n, mean=rep(0, dim.p), sigma=A)
theta = matrix(1, ncol=1, nrow=dim.p)
epsilon = rnorm(dim.n, mean=0, sd=1)
# Data generation
y = X %*% theta  + epsilon
return(list(Y=y, X=X, A=A, theta=theta))
}
check.data <- function(data) {
# Do this to check the data object.
#
nx = nrow(data$X)
ny = length(data$Y)
p = ncol(data$X)
stopifnot(nx==ny, p==length(data$theta))
lambdas = eigen(cov(data$X))$values
print(lambdas)
print(mean(data$Y))
print(var(data$Y))
print(1 + sum(cov(data$X)))
}
plot.risk <- function(data, est) {
# est = p x niters
est.bias = apply(est, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
plot(est.bias, type="l", lty=3)
}
sgd <- function(data, plot=T) {
# check.data(data)
n = nrow(data$X)
p = ncol(data$X)
I = diag(p)
# matrix of estimates of SGD (p x iters)
theta.sgd = matrix(0, nrow = p, ncol = n)
# params for the learning rate seq.
gamma0 = 1 / (sum(seq(0.01, 1, length.out=p)))
lambda0 = 0.01  #gamma0
for(i in 1:(n-1)) {
xi = data$X[i, ]
theta.old = theta.sgd[, i]
ai = gamma0 / (1 + gamma0 * lambda0 * i)
# make computations easier.
lpred = sum(theta.old * xi)
theta.new = (theta.old - ai * lpred * xi) + ai * data$Y[i] * xi
theta.sgd[, i+1] = theta.new
}
if(plot) {
plot.risk(data, theta.sgd)
} else {
return(theta.sgd)
}
}
sgd.im <- function(data, plot=T) {
# check.data(data)
n = nrow(data$X)
p = ncol(data$X)
I = diag(p)
# matrix of estimates of SGD (p x iters)
theta.sgd = matrix(0, nrow = p, ncol = n)
# params for the learning rate seq.
gamma0 = 1 / (sum(seq(0.01, 1, length.out=p)))
lambda0 = gamma0  #0.01
for(i in 1:(n-1)) {
xi = data$X[i, ]
theta.old = theta.sgd[, i]
ai = 1 / ( lambda0 + lambda0 * i)
# make computations easier.
inner = sum(xi^2)
ratio = 1/(1+inner*ai)
lpred = sum(theta.old * xi)
theta.new = theta.old + ai*(data$Y[i]-lpred*ratio-ai*data$Y[i]*ratio*inner)*xi
theta.sgd[, i+1] = theta.new
}
if(plot) {
plot.risk(data, theta.sgd)
} else {
return(theta.sgd)
}
}
asgd <- function(data, plot=T) {
# check.data(data)
n = nrow(data$X)
p = ncol(data$X)
# matrix of estimates of SGD (p x iters)
theta.asgd = matrix(0, nrow = p, ncol = n)
theta.sgd = matrix(0, nrow = p, ncol = 1)
# params for the learning rate seq.
gamma0 = 1 / (sum(seq(0.01, 1, length.out=p)))
lambda0 = 0.01  #gamma0
for(i in 1:(n-1)) {
xi = data$X[i, ]
theta.old = theta.sgd[, 1]
ai = gamma0 / (1 + gamma0 * lambda0 * i)
# make computations easier.
lpred = sum(theta.old * xi)
theta.new = (theta.old - ai * lpred * xi) + ai * data$Y[i] * xi
theta.sgd[, 1] = theta.new
theta.asgd[, i+1] = (1-(1/(i+1)))*theta.asgd[, i] + 1/(i+1)*theta.new
}
if(plot) {
plot.risk(data, theta.asgd)
} else {
return(theta.asgd)
}
}
batch <- function(data, plot=T) {
# check.data(data)
n = nrow(data$X)
p = ncol(data$X)
# matrix of estimates of SGD (p x iters)
theta.batch = matrix(0, nrow = p, ncol = n)
for(i in 1:n) {
if (i > 100){
if (i %% 1000 == 0){
fit = lm(data$Y[1:i] ~ data$X[1:i, ])
theta.batch[, i] = coef(fit)[2:(p+1)]
}
else{
theta.batch[, i] = theta.batch[, i-1]
}
}
}
if(plot) {
plot.risk(data, theta.batch)
} else {
return(theta.batch)
}
}
d = sample.data(1e5, 100)
theta.sgd = sgd(d, F)
theta.sgd.im = sgd.im(d, F)
theta.asgd = asgd(d, F)
theta.batch = batch(d, F)
plot.all <- function(data, est){
est$sgd = apply(est$sgd, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
est$asgd = apply(est$asgd, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
est$sgd.im = apply(est$sgd.im, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
est$batch = apply(est$batch, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
x = matrix(seq(1, length(est[[1]])))
agg = data.frame(est, x)
agg = melt(agg, id = 'x')
ggplot(agg, aes(x = x, y = value, color = variable)) + geom_line()+scale_x_log10()+
+theme(axis.title.x = element_text(size=20),axis.text.x= element_text(size=15),axis.title.y = element_text(size=20),axis.text.y= element_text(size=15))
ggsave(file='fig/lan_tian_ps2_task2a.png', width=2, heigh=2, dpi=300)
}
plot.all(d, list('sgd'=theta.sgd, 'sgd.im'=theta.sgd.im, 'asgd'=theta.asgd, 'batch'=theta.batch))
plot.all(d, list('sgd'=theta.sgd, 'sgd.im'=theta.sgd.im, 'asgd'=theta.asgd, 'batch'=theta.batch))
plot.all <- function(data, est){
est$sgd = apply(est$sgd, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
est$asgd = apply(est$asgd, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
est$sgd.im = apply(est$sgd.im, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
est$batch = apply(est$batch, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
x = matrix(seq(1, length(est[[1]])))
agg = data.frame(est, x)
agg = melt(agg, id = 'x')
ggplot(agg, aes(x = x, y = value, color = variable)) + geom_line()+scale_x_log10()
ggsave(file='fig/lan_tian_ps2_task2a.png', width=2, heigh=2, dpi=300)
}
plot.all(d, list('sgd'=theta.sgd, 'sgd.im'=theta.sgd.im, 'asgd'=theta.asgd, 'batch'=theta.batch))
plot.all(d, list('sgd'=theta.sgd, 'sgd.im'=theta.sgd.im, 'asgd'=theta.asgd, 'batch'=theta.batch))
plot.all <- function(data, est){
est$sgd = apply(est$sgd, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
est$asgd = apply(est$asgd, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
est$sgd.im = apply(est$sgd.im, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
est$batch = apply(est$batch, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
x = matrix(seq(1, length(est[[1]])))
agg = data.frame(est, x)
agg = melt(agg, id = 'x')
ggplot(agg, aes(x = x, y = value, color = variable)) + geom_line()+scale_x_log10()
ggsave(file='fig/lan_tian_ps2_task2a.png', width=5, heigh=5, dpi=100)
}
plot.all(d, list('sgd'=theta.sgd, 'sgd.im'=theta.sgd.im, 'asgd'=theta.asgd, 'batch'=theta.batch))
args <- as.numeric(commandArgs(trailingOnly = TRUE))
if(length(args) != 1) {
args[1] = 1
}
job.id = args[1]
select = job.id%%3
if (select == 0)
select = 3
source('lan_tian_ps3_functions.R')
sample.data <- function(dim.n, dim.p, model="gaussian") {
# Samples the covariates as normal with the specific correlation
# Create A matrix (variance of the covariates xn)
Q = random.orthogonal(p=dim.p)
lambdas = seq(0.01, 1, length.out=dim.p)
A = Q %*% diag(lambdas) %*% t(Q)
X = rmvnorm(dim.n, mean=rep(0, dim.p), sigma=A)
theta = matrix(1, ncol=1, nrow=dim.p)
epsilon = rnorm(dim.n, mean=0, sd=1)
# Data generation
y = X %*% theta  + epsilon
return(list(Y=y, X=X, A=A, theta=theta))
}
check.data <- function(data) {
# Do this to check the data object.
#
nx = nrow(data$X)
ny = length(data$Y)
p = ncol(data$X)
stopifnot(nx==ny, p==length(data$theta))
lambdas = eigen(cov(data$X))$values
print(lambdas)
print(mean(data$Y))
print(var(data$Y))
print(1 + sum(cov(data$X)))
}
plot.risk <- function(data, est) {
# est = p x niters
est.bias = apply(est, 2, function(colum)
log(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
plot(est.bias, type="l", lty=3)
}
sgd <- function(data, plot=T) {
# check.data(data)
n = nrow(data$X)
p = ncol(data$X)
I = diag(p)
# matrix of estimates of SGD (p x iters)
theta.sgd = matrix(0, nrow = p, ncol = n)
# params for the learning rate seq.
gamma0 = 1 / (sum(seq(0.01, 1, length.out=p)))
lambda0 = 0.01  #gamma0
for(i in 1:(n-1)) {
xi = data$X[i, ]
theta.old = theta.sgd[, i]
ai = gamma0 / (1 + gamma0 * lambda0 * i)
# make computations easier.
lpred = sum(theta.old * xi)
theta.new = (theta.old - ai * lpred * xi) + ai * data$Y[i] * xi
theta.sgd[, i+1] = theta.new
}
if(plot) {
plot.risk(data, theta.sgd)
} else {
return(theta.sgd)
}
}
sgd.im <- function(data, plot=T) {
# check.data(data)
n = nrow(data$X)
p = ncol(data$X)
I = diag(p)
# matrix of estimates of SGD (p x iters)
theta.sgd = matrix(0, nrow = p, ncol = n)
# params for the learning rate seq.
gamma0 = 1 / (sum(seq(0.01, 1, length.out=p)))
lambda0 = gamma0  #0.01
for(i in 1:(n-1)) {
xi = data$X[i, ]
theta.old = theta.sgd[, i]
ai = 1 / ( lambda0 + lambda0 * i)
# make computations easier.
inner = sum(xi^2)
ratio = 1/(1+inner*ai)
lpred = sum(theta.old * xi)
theta.new = theta.old + ai*(data$Y[i]-lpred*ratio-ai*data$Y[i]*ratio*inner)*xi
theta.sgd[, i+1] = theta.new
}
if(plot) {
plot.risk(data, theta.sgd)
} else {
return(theta.sgd)
}
}
asgd <- function(data, plot=T) {
# check.data(data)
n = nrow(data$X)
p = ncol(data$X)
# matrix of estimates of SGD (p x iters)
theta.asgd = matrix(0, nrow = p, ncol = n)
theta.sgd = matrix(0, nrow = p, ncol = 1)
# params for the learning rate seq.
gamma0 = 1 / (sum(seq(0.01, 1, length.out=p)))
lambda0 = 0.01  #gamma0
for(i in 1:(n-1)) {
xi = data$X[i, ]
theta.old = theta.sgd[, 1]
ai = gamma0 / (1 + gamma0 * lambda0 * i)
# make computations easier.
lpred = sum(theta.old * xi)
theta.new = (theta.old - ai * lpred * xi) + ai * data$Y[i] * xi
theta.sgd[, 1] = theta.new
theta.asgd[, i+1] = (1-(1/(i+1)))*theta.asgd[, i] + 1/(i+1)*theta.new
}
if(plot) {
plot.risk(data, theta.asgd)
} else {
return(theta.asgd)
}
}
batch <- function(data, plot=T) {
# check.data(data)
n = nrow(data$X)
p = ncol(data$X)
# matrix of estimates of SGD (p x iters)
theta.batch = matrix(0, nrow = p, ncol = n)
for(i in 1:n) {
if (i > 100){
if (i %% 1000 == 0){
fit = lm(data$Y[1:i] ~ data$X[1:i, ])
theta.batch[, i] = coef(fit)[2:(p+1)]
}
else{
theta.batch[, i] = theta.batch[, i-1]
}
}
}
if(plot) {
plot.risk(data, theta.batch)
} else {
return(theta.batch)
}
}
methods = c(sgd, sgd.im, asgd)
d = sample.data(1e4)
d = sample.data(1e4, 100)
test = methods[[1]](d)
